{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 개요\n",
    "\n",
    "    + 파이썬으로 구현된 쉽고 간결한 딥러닝 라이브러리\n",
    "    + 프랑소와 숄레가 2015년 3월에 발표\n",
    "    + 내부적으로는 텐서플로 엔진이 구동되지만 직관적인API로 쉽게 딥러닝\n",
    "    실험을 할 수 있도록 지원\n",
    "    \n",
    "## 2. 주요 특징\n",
    "\n",
    "    + 모듈화 : 독립적인 모듈들을 조합하여 구현\n",
    "    + 최소주의 : 각 모듈을 짧고 간결\n",
    "    + 쉬운 확장성 : 클래스나 함수로 모듈을 쉽게 추가 할 수 있다.\n",
    "    + 파이썬 기반 : 별도의 설정이 필요없다.\n",
    "    \n",
    "## 3.설치\n",
    "\n",
    "    pip uninstall keras\n",
    "    pip install keras==2.3.1\n",
    "    \n",
    "## 4.API\n",
    "\n",
    "    1. 준비\n",
    "        Sequential()\n",
    "        \n",
    "    2. 계층 설정\n",
    "        Dense()\n",
    "        \n",
    "    3. 컴파일\n",
    "        compile()\n",
    "    4. 학습(훈련)\n",
    "        fit()\n",
    "    5. 평가\n",
    "        evaluate()\n",
    "    6. 예측 \n",
    "        predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "font_name = fm.FontProperties(fname = 'C:\\\\Windows\\\\Fonts\\\\malgun.ttf').get_name()\n",
    "plt.rc('font', family = font_name)\n",
    "\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "#CNN\n",
    "from keras.datasets import mnist\n",
    "from keras import layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 과거 텐서플로만 사용하여 한 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 준비\n",
    "x_train = [1,2,3,4,5]\n",
    "y_train = [2.1,3.1,4.1,5.1,6.1]\n",
    "\n",
    "# 데이터 준비\n",
    "x_train = tf.placeholder(tf.float32, shape = [None])\n",
    "y_train = tf.placeholder(tf.float32, shape = [None])\n",
    "\n",
    "#가설 준비 : WX +b\n",
    "W = tf.Variable(tf.random_normal([1]), dtype = tf.float32)\n",
    "b = tf.Variable(tf.random_normal([1]), dtype = tf.float32)\n",
    "\n",
    "hypot = W*x_train +b\n",
    "\n",
    "#비용함수\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypot - y_train))\n",
    "# 최저 비용 학습을 위한 경사하강알고리즘\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "#----------------- 텐서플로우의 그래프 작성 완료\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    _, c, w, b1 = sess.run([train, cost, W,b], feed_dict ={x_train:[1,2,3,4,5],\n",
    "                                                      y_train:[2.1,3.1,4.1,5.1,6.1]})\n",
    "    if step%500 ==0:\n",
    "        print(step, c, w, b1)\n",
    "    \n",
    "# Testing\n",
    "print(sess.run(hypot, feed_dict={x_train:[27]}))\n",
    "print(sess.run(hypot, feed_dict={x_train:[2.5,3.7]}))\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sequential 모데을 레이어를 선형적으로 쌓는다. \n",
    "- .add() 를 통해 레이어를 쌓을수있다., input_dim 인수로 최초의 레이어 입력크기 설정\n",
    "- activation 인수로 활성화 함수 설정\n",
    "model.add(Dense(units=64, activation='relu', input_dim=100))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "- .compile() 학습과정을 조정할수있다. , 옵티마이저까지 조정가능\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics['accuracy'])\n",
    "### compile 에서 메트릭 : 평가 기준이고 사용자 정의 메트릭을 사용가능하다.\n",
    "### model. predict(np.array([예측할 값])\n",
    "### predict(x, batch_size=None, verbose=0, steps=None, callbacks=None)\n",
    "    - x : Numpy 배열 형태의 인풋 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 준비\n",
    "x_train = [1,2,3,4,5]\n",
    "y_train = [2.1,3.1,4.1,5.1,6.1]\n",
    "\n",
    "#모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_shape = (1,)))\n",
    "# model.compile(loss = \"mse\", optimizer=\"rmsprop\", metrics = [\"accuracy\"])\n",
    "# RMSprop 객체를 이용하여 learning rate조정가능\n",
    "model.compile(loss = \"mse\", optimizer=RMSprop(lr=0.01), metrics = [\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model_result=model.fit(x_train, y_train, epochs = 1000 )\n",
    "print(model_result.history[\"loss\"]) #lostt값들쭉 나옴\n",
    "\n",
    "model.predict(x_train)\n",
    "# 예측 어떻게 하는지 \n",
    "model.predict(np.array([27,2.5,3.7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.array로 해줘야함\n",
    "X = np.array([[73., 80., 75.], [93., 88., 93.],\n",
    "         [89., 91., 90.], [96., 98., 100.], [73., 66., 70.]])\n",
    "y = np.array([[152.],[185.],[180.],[196.],[142.]])\n",
    "# 출력의 개수 1개 입력의 개수 3\n",
    "model = Sequential([Dense(1, input_shape=(3,))])\n",
    "model.compile(loss=\"mse\", optimizer = RMSprop(lr = 0.01))\n",
    "\n",
    "model.fit(X, y, epochs = 1000, batch_size = 1 )\n",
    "\n",
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09.txt (파일) :  Age, Weigth, 혈당 등등있는 25x 5 \n",
    "\n",
    "참고 \n",
    "- https://sdc-james.gitbook.io/onebook/4.-and/5.4.-tensorflow/5.4.1.-keras\n",
    "2. 참고\n",
    "    - https://pinkwink.kr/1082?category=580892"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혈당 수치 예측\n",
    "# skip_header 로 스킵\n",
    "data = np.genfromtxt(\"data/x09.txt\", skip_header = 36)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체중이 100 이고 나이가 40일떄의 혈당은?\n",
    "dataframe = pd.DataFrame(data)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = array[:, 2:4]\n",
    "y = array[:, 4:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "model = Sequential([Dense(1, input_shape=(2,))])\n",
    "model.compile(loss=\"mse\", optimizer = RMSprop(lr = 0.01))\n",
    "model.fit(X, y, epochs = 1000, batch_size = 1 )\n",
    "\n",
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"100Kg, 40세\", model.predict(np.array([100,40]).reshape(1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선생님꺼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혈당 수치 예측\n",
    "# skip_header 로 스킵\n",
    "data = np.genfromtxt(\"data/x09.txt\", skip_header = 36)\n",
    "\n",
    "X = data[:, 2:4]\n",
    "y = data[:, 4:5]\n",
    "\n",
    "model = Sequential([Dense(1, input_shape=(2,))])\n",
    "model.compile(loss=\"mse\", optimizer = RMSprop(lr = 0.01))\n",
    "hist = model.fit(X, y, epochs = 400, batch_size = 1 )\n",
    "# loss의 변화를 알고싶다. \n",
    "plt.plot(hist.history[\"loss\"])\n",
    "# np.array([100,40]) 안되는이유 1차원이라서\n",
    "model.predict(np.array([100,40]).reshape(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 보스턴 주택 가격 예측\n",
    "\n",
    "from keras.datasets import boston_housing\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0:5]\n",
    "# 표준화를 직접 해본 코드 standardization\n",
    "mean = X_train.mean(axis = 0)\n",
    "X_train -= mean\n",
    "std = X_train.std(axis = 0)\n",
    "X_train /= std\n",
    "X_test -= mean\n",
    "X_test /= std\n",
    "\n",
    "X_train[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다양한 activation 들이 있음\n",
    "- softmax, elu, relu, sigmoid, linear 등등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape = (X_train.shape[1],), activation =\"relu\"))\n",
    "# 자동적으로 입력개수 만들어준다. 2번째 계층부터 inputshape 할필요없음\n",
    "# 이번에도 출력개수 64개로 하겠다.\n",
    "model.add(Dense(64,activation =\"relu\"))\n",
    "model.add(Dense(1)) #최종 출력개수 1\n",
    "\n",
    "model.summary()\n",
    "# mse 평균 제곱 오차 예측과 타깃 사이의 거리의 제곱\n",
    "# 훈련 모니터링을 위해 새로운 지표인 평균 절대 오차 \n",
    "# Mean Absolute Error 예를들어 0.5이면 평균적으로 500달러 정도 차이\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer = \"rmsprop\", metrics = [\"mae\"])\n",
    "model.fit(X_train, y_train, epochs = 100, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 측정도구 mae \n",
    "mse, mae=model.evaluate(X_test, y_test)\n",
    "print(mse, mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OR gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 준비\n",
    "X = np.array([[0, 0, 0], \n",
    "                   [0, 0, 1], \n",
    "                   [0, 1, 0], \n",
    "                   [0, 1, 1], \n",
    "                   [1, 0, 0],\n",
    "                   [1, 1, 0],\n",
    "                   [1, 0, 1], \n",
    "                   [1, 1, 1]], \n",
    "                  dtype=np.float32)                   \n",
    "y = np.array([[0], [1], [1], [1], [1], [1], [1], [1]], dtype=np.float32)\n",
    "# units 출력의 개수 1 , input_shape 입력의개수\n",
    "model = Sequential([Dense(units =1 , input_shape=(3,), activation=\"sigmoid\")])\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer =\"rmsprop\",\n",
    "              metrics = [\"accuracy\"])\n",
    "model.fit(X,y,epochs=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mnist 손글씨 사례\n",
    "    참고 -\n",
    "    - https://datascienceschool.net/view-notebook/51e147088d474fe1bf32e394394eaea7/\n",
    "\n",
    "    참고 - https://m.blog.naver.com/PostView.nhn?blogId=ksg97031&logNo=221302568510&proxyReferer=https:%2F%2Fwww.google.com%2F\n",
    "    \n",
    "    비슷코드 - \n",
    "    https://hdongle.tistory.com/47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train= np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 데이터 스케일 조정\n",
    "X_train = X_train.reshape(60000, 28*28).astype(\"float32\")/255\n",
    "X_test = X_test.reshape(10000, 28*28).astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation 분할\n",
    "X_val = X_train[:12600]\n",
    "X_train = X_train[12600:]\n",
    "y_val = y_train[:12600]\n",
    "y_train = y_train[12600:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\acorn\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 구성 \n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, input_shape =(28*28,), activation = \"relu\"))\n",
    "#입력은 자동이라 안써도됨 input_shape = (64,)\n",
    "#relu는 0 보다 작은값은 0으로 반환하고 0보다 큰 값이 나온경우 그값을\n",
    "#\"그대로\" 반환하는 함수이다. max(0, x) \n",
    "#Sigmoid는 0~1 사이값만 다루므로 계속 곱하면 0에 수렵한다.\n",
    "#1보다 작아지지 않게 \n",
    "model.add(Dense(units = 10, activation = \"softmax\"))\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\acorn\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 47400 samples, validate on 12600 samples\n",
      "Epoch 1/50\n",
      "47400/47400 [==============================] - 2s 35us/step - loss: 0.7701 - accuracy: 0.8022 - val_loss: 0.4152 - val_accuracy: 0.8889\n",
      "Epoch 2/50\n",
      "47400/47400 [==============================] - 2s 33us/step - loss: 0.3807 - accuracy: 0.8942 - val_loss: 0.3377 - val_accuracy: 0.9075\n",
      "Epoch 3/50\n",
      "47400/47400 [==============================] - 2s 32us/step - loss: 0.3281 - accuracy: 0.9073 - val_loss: 0.3075 - val_accuracy: 0.9136\n",
      "Epoch 4/50\n",
      "47400/47400 [==============================] - 2s 33us/step - loss: 0.2991 - accuracy: 0.9145 - val_loss: 0.2813 - val_accuracy: 0.9215\n",
      "Epoch 5/50\n",
      "47400/47400 [==============================] - 2s 32us/step - loss: 0.2769 - accuracy: 0.9211 - val_loss: 0.2714 - val_accuracy: 0.9240\n",
      "Epoch 6/50\n",
      "47400/47400 [==============================] - 1s 31us/step - loss: 0.2584 - accuracy: 0.9272 - val_loss: 0.2535 - val_accuracy: 0.9281\n",
      "Epoch 7/50\n",
      "47400/47400 [==============================] - 1s 31us/step - loss: 0.2429 - accuracy: 0.9313 - val_loss: 0.2380 - val_accuracy: 0.9346\n",
      "Epoch 8/50\n",
      "47400/47400 [==============================] - 1s 30us/step - loss: 0.2290 - accuracy: 0.9360 - val_loss: 0.2259 - val_accuracy: 0.9369\n",
      "Epoch 9/50\n",
      "47400/47400 [==============================] - 1s 32us/step - loss: 0.2165 - accuracy: 0.9402 - val_loss: 0.2152 - val_accuracy: 0.9397\n",
      "Epoch 10/50\n",
      "47400/47400 [==============================] - 1s 31us/step - loss: 0.2055 - accuracy: 0.9430 - val_loss: 0.2065 - val_accuracy: 0.9410\n",
      "Epoch 11/50\n",
      "47400/47400 [==============================] - 2s 32us/step - loss: 0.1958 - accuracy: 0.9456 - val_loss: 0.1982 - val_accuracy: 0.9437\n",
      "Epoch 12/50\n",
      "47400/47400 [==============================] - 2s 32us/step - loss: 0.1868 - accuracy: 0.9483 - val_loss: 0.1917 - val_accuracy: 0.9433\n",
      "Epoch 13/50\n",
      "47400/47400 [==============================] - 2s 33us/step - loss: 0.1787 - accuracy: 0.9508 - val_loss: 0.1863 - val_accuracy: 0.9460\n",
      "Epoch 14/50\n",
      "47400/47400 [==============================] - 2s 32us/step - loss: 0.1714 - accuracy: 0.9532 - val_loss: 0.1787 - val_accuracy: 0.9479\n",
      "Epoch 15/50\n",
      "47400/47400 [==============================] - 2s 33us/step - loss: 0.1650 - accuracy: 0.9540 - val_loss: 0.1736 - val_accuracy: 0.9497\n",
      "Epoch 16/50\n",
      "47400/47400 [==============================] - 1s 31us/step - loss: 0.1586 - accuracy: 0.9559 - val_loss: 0.1696 - val_accuracy: 0.9508\n",
      "Epoch 17/50\n",
      "47400/47400 [==============================] - 1s 31us/step - loss: 0.1530 - accuracy: 0.9580 - val_loss: 0.1660 - val_accuracy: 0.9518\n",
      "Epoch 18/50\n",
      "47400/47400 [==============================] - 2s 33us/step - loss: 0.1475 - accuracy: 0.9590 - val_loss: 0.1606 - val_accuracy: 0.9539\n",
      "Epoch 19/50\n",
      "47400/47400 [==============================] - 1s 31us/step - loss: 0.1426 - accuracy: 0.9604 - val_loss: 0.1570 - val_accuracy: 0.9545\n",
      "Epoch 20/50\n",
      "47400/47400 [==============================] - 1s 31us/step - loss: 0.1381 - accuracy: 0.9619 - val_loss: 0.1533 - val_accuracy: 0.9552\n",
      "Epoch 21/50\n",
      "47400/47400 [==============================] - 1s 32us/step - loss: 0.1335 - accuracy: 0.9630 - val_loss: 0.1518 - val_accuracy: 0.9556\n",
      "Epoch 22/50\n",
      "47400/47400 [==============================] - 1s 30us/step - loss: 0.1295 - accuracy: 0.9639 - val_loss: 0.1477 - val_accuracy: 0.9574\n",
      "Epoch 23/50\n",
      "47400/47400 [==============================] - 1s 31us/step - loss: 0.1258 - accuracy: 0.9651 - val_loss: 0.1446 - val_accuracy: 0.9578\n",
      "Epoch 24/50\n",
      "47400/47400 [==============================] - 1s 31us/step - loss: 0.1223 - accuracy: 0.9659 - val_loss: 0.1418 - val_accuracy: 0.9594\n",
      "Epoch 25/50\n",
      "47400/47400 [==============================] - 1s 30us/step - loss: 0.1188 - accuracy: 0.9671 - val_loss: 0.1396 - val_accuracy: 0.9593\n",
      "Epoch 26/50\n",
      "47400/47400 [==============================] - 2s 32us/step - loss: 0.1155 - accuracy: 0.9682 - val_loss: 0.1380 - val_accuracy: 0.9598\n",
      "Epoch 27/50\n",
      "47400/47400 [==============================] - 2s 32us/step - loss: 0.1126 - accuracy: 0.9696 - val_loss: 0.1362 - val_accuracy: 0.9597\n",
      "Epoch 28/50\n",
      "47400/47400 [==============================] - 1s 31us/step - loss: 0.1097 - accuracy: 0.9699 - val_loss: 0.1352 - val_accuracy: 0.9601\n",
      "Epoch 29/50\n",
      "47400/47400 [==============================] - 2s 32us/step - loss: 0.1071 - accuracy: 0.9711 - val_loss: 0.1322 - val_accuracy: 0.9609\n",
      "Epoch 30/50\n",
      "47400/47400 [==============================] - 2s 32us/step - loss: 0.1045 - accuracy: 0.9714 - val_loss: 0.1303 - val_accuracy: 0.9609\n",
      "Epoch 31/50\n",
      "47400/47400 [==============================] - 2s 32us/step - loss: 0.1020 - accuracy: 0.9722 - val_loss: 0.1298 - val_accuracy: 0.9621\n",
      "Epoch 32/50\n",
      "47400/47400 [==============================] - 2s 33us/step - loss: 0.0994 - accuracy: 0.9731 - val_loss: 0.1266 - val_accuracy: 0.9637\n",
      "Epoch 33/50\n",
      "47400/47400 [==============================] - 1s 32us/step - loss: 0.0973 - accuracy: 0.9737 - val_loss: 0.1262 - val_accuracy: 0.9629\n",
      "Epoch 34/50\n",
      "47400/47400 [==============================] - 2s 33us/step - loss: 0.0950 - accuracy: 0.9743 - val_loss: 0.1244 - val_accuracy: 0.9638\n",
      "Epoch 35/50\n",
      "47400/47400 [==============================] - 2s 32us/step - loss: 0.0931 - accuracy: 0.9750 - val_loss: 0.1247 - val_accuracy: 0.9630\n",
      "Epoch 36/50\n",
      "47400/47400 [==============================] - 2s 32us/step - loss: 0.0909 - accuracy: 0.9758 - val_loss: 0.1244 - val_accuracy: 0.9640\n",
      "Epoch 37/50\n",
      "47400/47400 [==============================] - 2s 32us/step - loss: 0.0890 - accuracy: 0.9761 - val_loss: 0.1203 - val_accuracy: 0.9650\n",
      "Epoch 38/50\n",
      "47400/47400 [==============================] - 1s 31us/step - loss: 0.0872 - accuracy: 0.9767 - val_loss: 0.1192 - val_accuracy: 0.9648\n",
      "Epoch 39/50\n",
      "47400/47400 [==============================] - 2s 33us/step - loss: 0.0854 - accuracy: 0.9772 - val_loss: 0.1195 - val_accuracy: 0.9653\n",
      "Epoch 40/50\n",
      "47400/47400 [==============================] - 2s 32us/step - loss: 0.0837 - accuracy: 0.9784 - val_loss: 0.1194 - val_accuracy: 0.9645\n",
      "Epoch 41/50\n",
      "47400/47400 [==============================] - 2s 32us/step - loss: 0.0822 - accuracy: 0.9784 - val_loss: 0.1172 - val_accuracy: 0.9657\n",
      "Epoch 42/50\n",
      "47400/47400 [==============================] - 2s 33us/step - loss: 0.0804 - accuracy: 0.9785 - val_loss: 0.1169 - val_accuracy: 0.9663\n",
      "Epoch 43/50\n",
      "47400/47400 [==============================] - 2s 32us/step - loss: 0.0789 - accuracy: 0.9796 - val_loss: 0.1183 - val_accuracy: 0.9641\n",
      "Epoch 44/50\n",
      "47400/47400 [==============================] - 1s 32us/step - loss: 0.0775 - accuracy: 0.9796 - val_loss: 0.1137 - val_accuracy: 0.9663\n",
      "Epoch 45/50\n",
      "47400/47400 [==============================] - 1s 31us/step - loss: 0.0758 - accuracy: 0.9803 - val_loss: 0.1136 - val_accuracy: 0.9671\n",
      "Epoch 46/50\n",
      "47400/47400 [==============================] - 2s 32us/step - loss: 0.0744 - accuracy: 0.9807 - val_loss: 0.1115 - val_accuracy: 0.9682\n",
      "Epoch 47/50\n",
      "47400/47400 [==============================] - 2s 33us/step - loss: 0.0732 - accuracy: 0.9807 - val_loss: 0.1115 - val_accuracy: 0.9677\n",
      "Epoch 48/50\n",
      "47400/47400 [==============================] - 2s 33us/step - loss: 0.0719 - accuracy: 0.9814 - val_loss: 0.1094 - val_accuracy: 0.9680\n",
      "Epoch 49/50\n",
      "47400/47400 [==============================] - 2s 33us/step - loss: 0.0705 - accuracy: 0.9818 - val_loss: 0.1111 - val_accuracy: 0.9675\n",
      "Epoch 50/50\n",
      "47400/47400 [==============================] - 2s 32us/step - loss: 0.0691 - accuracy: 0.9818 - val_loss: 0.1081 - val_accuracy: 0.9684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x16780055d48>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 50, batch_size = 32, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 16us/step\n",
      "[0.09721958452332764, 0.9713000059127808]\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(X_test, y_test, batch_size=32)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9412,  537, 5699, 4307,  919, 1372, 7566, 2583, 4441, 3239])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "\n",
    "xhat_idx = np.random.choice(X_test.shape[0], 10)\n",
    "xhat_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x hat 수학기호에서 x위에 꺽세 표시하는 수학기호 따서 변수이름설정\n",
    "xhat = X_test[xhat_idx]\n",
    "xhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 1, 5, 2, 2, 0, 3, 6, 2], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model.predict_classes(xhat)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True :  4 , Predict :  4\n",
      "True :  1 , Predict :  1\n",
      "True :  1 , Predict :  1\n",
      "True :  5 , Predict :  5\n",
      "True :  2 , Predict :  2\n",
      "True :  2 , Predict :  2\n",
      "True :  0 , Predict :  0\n",
      "True :  3 , Predict :  3\n",
      "True :  6 , Predict :  6\n",
      "True :  2 , Predict :  2\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"True : \", np.argmax(y_test[xhat_idx[i]]), \", Predict : \", yhat[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서보드 설정\n",
    "## 텐서플로우가 제공하는 시각화 도구\n",
    "    - 동적그래프나 모델 내 다양한 레이어에 대한 활성화 히스토그램을 시각화\n",
    "    -log_dir: TensorBoard가 구문 분석할 로그 파일을 저장할 위치 경로.\n",
    "    -write_graph: TensorBoard에서 그래프를 시각화할지 여부\n",
    "    -write_images: TensorBoard에서 이미지로 시각화할 모델 가중치를 작성할지 여부."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47400 samples, validate on 12600 samples\n",
      "Epoch 1/50\n",
      "47400/47400 [==============================] - 2s 34us/step - loss: 0.7235 - accuracy: 0.8099 - val_loss: 0.4036 - val_accuracy: 0.8921\n",
      "Epoch 2/50\n",
      "47400/47400 [==============================] - 2s 37us/step - loss: 0.3662 - accuracy: 0.8978 - val_loss: 0.3218 - val_accuracy: 0.9103\n",
      "Epoch 3/50\n",
      "47400/47400 [==============================] - 2s 37us/step - loss: 0.3122 - accuracy: 0.9114 - val_loss: 0.2879 - val_accuracy: 0.9199\n",
      "Epoch 4/50\n",
      "47400/47400 [==============================] - 2s 34us/step - loss: 0.2815 - accuracy: 0.9193 - val_loss: 0.2681 - val_accuracy: 0.9242\n",
      "Epoch 5/50\n",
      "47400/47400 [==============================] - 2s 38us/step - loss: 0.2595 - accuracy: 0.9260 - val_loss: 0.2488 - val_accuracy: 0.9294\n",
      "Epoch 6/50\n",
      "47400/47400 [==============================] - 2s 37us/step - loss: 0.2418 - accuracy: 0.9315 - val_loss: 0.2338 - val_accuracy: 0.9340\n",
      "Epoch 7/50\n",
      "47400/47400 [==============================] - 2s 36us/step - loss: 0.2264 - accuracy: 0.9359 - val_loss: 0.2219 - val_accuracy: 0.9368\n",
      "Epoch 8/50\n",
      "47400/47400 [==============================] - 2s 37us/step - loss: 0.2133 - accuracy: 0.9399 - val_loss: 0.2107 - val_accuracy: 0.9397\n",
      "Epoch 9/50\n",
      "47400/47400 [==============================] - 2s 36us/step - loss: 0.2020 - accuracy: 0.9427 - val_loss: 0.2021 - val_accuracy: 0.9419\n",
      "Epoch 10/50\n",
      "47400/47400 [==============================] - 2s 36us/step - loss: 0.1920 - accuracy: 0.9460 - val_loss: 0.1934 - val_accuracy: 0.9445\n",
      "Epoch 11/50\n",
      "47400/47400 [==============================] - 2s 36us/step - loss: 0.1831 - accuracy: 0.9483 - val_loss: 0.1864 - val_accuracy: 0.9456\n",
      "Epoch 12/50\n",
      "47400/47400 [==============================] - 2s 36us/step - loss: 0.1749 - accuracy: 0.9507 - val_loss: 0.1803 - val_accuracy: 0.9479\n",
      "Epoch 13/50\n",
      "47400/47400 [==============================] - 2s 36us/step - loss: 0.1677 - accuracy: 0.9528 - val_loss: 0.1739 - val_accuracy: 0.9490\n",
      "Epoch 14/50\n",
      "47400/47400 [==============================] - 2s 36us/step - loss: 0.1608 - accuracy: 0.9546 - val_loss: 0.1689 - val_accuracy: 0.9509\n",
      "Epoch 15/50\n",
      "47400/47400 [==============================] - 2s 37us/step - loss: 0.1547 - accuracy: 0.9560 - val_loss: 0.1646 - val_accuracy: 0.9521\n",
      "Epoch 16/50\n",
      "47400/47400 [==============================] - 2s 36us/step - loss: 0.1488 - accuracy: 0.9577 - val_loss: 0.1605 - val_accuracy: 0.9535\n",
      "Epoch 17/50\n",
      "47400/47400 [==============================] - 2s 37us/step - loss: 0.1436 - accuracy: 0.9597 - val_loss: 0.1555 - val_accuracy: 0.9537\n",
      "Epoch 18/50\n",
      "47400/47400 [==============================] - 2s 36us/step - loss: 0.1388 - accuracy: 0.9609 - val_loss: 0.1523 - val_accuracy: 0.9559\n",
      "Epoch 19/50\n",
      "47400/47400 [==============================] - 2s 37us/step - loss: 0.1341 - accuracy: 0.9622 - val_loss: 0.1489 - val_accuracy: 0.9563\n",
      "Epoch 20/50\n",
      "47400/47400 [==============================] - 2s 36us/step - loss: 0.1300 - accuracy: 0.9630 - val_loss: 0.1443 - val_accuracy: 0.9581\n",
      "Epoch 21/50\n",
      "47400/47400 [==============================] - 2s 37us/step - loss: 0.1260 - accuracy: 0.9643 - val_loss: 0.1413 - val_accuracy: 0.9587\n",
      "Epoch 22/50\n",
      "47400/47400 [==============================] - 2s 36us/step - loss: 0.1221 - accuracy: 0.9653 - val_loss: 0.1393 - val_accuracy: 0.9590\n",
      "Epoch 23/50\n",
      "47400/47400 [==============================] - 2s 37us/step - loss: 0.1184 - accuracy: 0.9666 - val_loss: 0.1372 - val_accuracy: 0.9604\n",
      "Epoch 24/50\n",
      "47400/47400 [==============================] - 2s 36us/step - loss: 0.1150 - accuracy: 0.9681 - val_loss: 0.1349 - val_accuracy: 0.9609\n",
      "Epoch 25/50\n",
      "47400/47400 [==============================] - 2s 36us/step - loss: 0.1120 - accuracy: 0.9687 - val_loss: 0.1324 - val_accuracy: 0.9610\n",
      "Epoch 26/50\n",
      "47400/47400 [==============================] - 2s 33us/step - loss: 0.1089 - accuracy: 0.9695 - val_loss: 0.1311 - val_accuracy: 0.9619\n",
      "Epoch 27/50\n",
      "47400/47400 [==============================] - 2s 36us/step - loss: 0.1061 - accuracy: 0.9702 - val_loss: 0.1283 - val_accuracy: 0.9637\n",
      "Epoch 28/50\n",
      "47400/47400 [==============================] - 2s 37us/step - loss: 0.1034 - accuracy: 0.9708 - val_loss: 0.1273 - val_accuracy: 0.9637\n",
      "Epoch 29/50\n",
      "47400/47400 [==============================] - 2s 36us/step - loss: 0.1009 - accuracy: 0.9715 - val_loss: 0.1242 - val_accuracy: 0.9640\n",
      "Epoch 30/50\n",
      "47400/47400 [==============================] - 2s 36us/step - loss: 0.0985 - accuracy: 0.9728 - val_loss: 0.1236 - val_accuracy: 0.9649\n",
      "Epoch 31/50\n",
      "47400/47400 [==============================] - 2s 36us/step - loss: 0.0961 - accuracy: 0.9732 - val_loss: 0.1214 - val_accuracy: 0.9659\n",
      "Epoch 32/50\n",
      "47400/47400 [==============================] - 2s 37us/step - loss: 0.0938 - accuracy: 0.9736 - val_loss: 0.1198 - val_accuracy: 0.9648\n",
      "Epoch 33/50\n",
      "47400/47400 [==============================] - 2s 36us/step - loss: 0.0917 - accuracy: 0.9747 - val_loss: 0.1196 - val_accuracy: 0.9644\n",
      "Epoch 34/50\n",
      "47400/47400 [==============================] - 2s 36us/step - loss: 0.0896 - accuracy: 0.9747 - val_loss: 0.1175 - val_accuracy: 0.9660\n",
      "Epoch 35/50\n",
      "47400/47400 [==============================] - 2s 33us/step - loss: 0.0878 - accuracy: 0.9756 - val_loss: 0.1154 - val_accuracy: 0.9663\n",
      "Epoch 36/50\n",
      "47400/47400 [==============================] - 2s 33us/step - loss: 0.0858 - accuracy: 0.9762 - val_loss: 0.1143 - val_accuracy: 0.9672\n",
      "Epoch 37/50\n",
      "47400/47400 [==============================] - 2s 37us/step - loss: 0.0839 - accuracy: 0.9769 - val_loss: 0.1136 - val_accuracy: 0.9677\n",
      "Epoch 38/50\n",
      "47400/47400 [==============================] - 2s 32us/step - loss: 0.0822 - accuracy: 0.9768 - val_loss: 0.1129 - val_accuracy: 0.9675\n",
      "Epoch 39/50\n",
      "47400/47400 [==============================] - 2s 36us/step - loss: 0.0805 - accuracy: 0.9775 - val_loss: 0.1127 - val_accuracy: 0.9668\n",
      "Epoch 40/50\n",
      "47400/47400 [==============================] - 2s 36us/step - loss: 0.0789 - accuracy: 0.9780 - val_loss: 0.1102 - val_accuracy: 0.9672\n",
      "Epoch 41/50\n",
      "47400/47400 [==============================] - 2s 33us/step - loss: 0.0773 - accuracy: 0.9784 - val_loss: 0.1107 - val_accuracy: 0.9683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x16782bc7c08>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "y_train= np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "# 이미지 데이터 스케일 조정\n",
    "X_train = X_train.reshape(60000, 28*28).astype(\"float32\")/255\n",
    "X_test = X_test.reshape(10000, 28*28).astype(\"float32\")/255\n",
    "# validation 분할\n",
    "X_val = X_train[:12600]\n",
    "X_train = X_train[12600:]\n",
    "y_val = y_train[:12600]\n",
    "y_train = y_train[12600:]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, input_shape =(28*28,), activation = \"relu\"))\n",
    "model.add(Dense(units = 10, activation = \"softmax\"))\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "\n",
    "#텐서보드 설정 \n",
    "tf_hist=keras.callbacks.TensorBoard(log_dir=\"./graph\", write_graph=True,\n",
    "                           write_images=True)\n",
    "#이거 ai폴더 , graph 폴더 있는곳까지 가서 실행해야함\n",
    "#텐서보드 설정: tensorboard --logdir=graph\n",
    "#localhost:6006 으로 접속\n",
    "\n",
    "#조기 종료 설정\n",
    "early = EarlyStopping()\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 50, batch_size = 32,\n",
    "          validation_data = (X_val, y_val),callbacks = [tf_hist, early])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델저장\n",
    "model.save(\"data/mnist_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 케라스 모델 객체\n",
    "# from keras.models import Sequential, load_model 에서 load_model 이용\n",
    "\n",
    "# 모델 재사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = load_model(\"data/mnist_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True :  5 , Predict :  5\n",
      "True :  8 , Predict :  4\n",
      "True :  9 , Predict :  9\n",
      "True :  9 , Predict :  9\n",
      "True :  9 , Predict :  9\n",
      "True :  9 , Predict :  9\n",
      "True :  0 , Predict :  0\n",
      "True :  9 , Predict :  9\n",
      "True :  5 , Predict :  5\n",
      "True :  8 , Predict :  8\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_test = X_test.reshape(10000, 28*28).astype(\"float32\")/255\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "xhat_idx = np.random.choice(X_test.shape[0], 10)\n",
    "xhat = X_test[xhat_idx]\n",
    "\n",
    "# 모델 2라고 해줘야함\n",
    "# yhat = model.predict_classes(xhat)\n",
    "yhat = model2.predict_classes(xhat)\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"True : \", np.argmax(y_test[xhat_idx[i]]), \", Predict : \", yhat[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from keras.callbacks import EarlyStopping\n",
    "\n",
    "# 조기 종료 : EarlyStopping(monitor = \"val_loss\", min_deta =0, patience =10)\n",
    "\n",
    "    1) monitor : 관찰하고자 하는 항목, 주록 val_loss나 vall_acc 주로 사용\n",
    "    2) min_delta : 개선되고 있다고 판단하기 위한 최소 변화량, 보통 0 지정\n",
    "    3) patience : 지정된 값까지 기다렸다가 종료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN 모듈화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_number, output_number, hidden_layer):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(hidden_layer[0], input_shape = (input_number,),\n",
    "                   activation = \"relu\"))\n",
    "    model.add(Dense(hidden_layer[1],activation = \"relu\"))\n",
    "    model.add(Dense(hidden_layer[2],activation = \"relu\"))\n",
    "    model.add(Dense(hidden_layer[3],activation = \"relu\"))\n",
    "    \n",
    "    # 성능향상을 위해 drop out 사용\n",
    "    model.add(keras.layers.core.Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(output_number, activation=\"softmax\"))\n",
    "    model.compile(loss =\"categorical_crossentropy\", optimizer = \"adam\",\n",
    "                 metrics = [\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.0819 - accuracy: 0.9774\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.0808 - accuracy: 0.9776\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.0800 - accuracy: 0.9778\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.0793 - accuracy: 0.9780\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.0786 - accuracy: 0.9782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x16788d17588>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# one hot 인코딩\n",
    "y_train= np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "#이미지 데이터 스케일 조정\n",
    "X_train = X_train.reshape(60000, 28*28).astype(\"float32\")/255\n",
    "X_test = X_test.reshape(10000, 28*28).astype(\"float32\")/255\n",
    "\n",
    "input_number = 784\n",
    "output_number = 10\n",
    "hidden_layer = [255, 255, 255, 255]\n",
    "\n",
    "make_model(input_number, output_number, hidden_layer)\n",
    "model.fit(X_train, y_train, epochs = 5, batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "0             5.1          3.5           1.4          0.2     setosa\n",
       "1             4.9          3.0           1.4          0.2     setosa\n",
       "2             4.7          3.2           1.3          0.2     setosa\n",
       "3             4.6          3.1           1.5          0.2     setosa\n",
       "4             5.0          3.6           1.4          0.2     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iris로 성능측정\n",
    "iris = sns.load_dataset(\"iris\")\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 또까먹냐? iloc [ 행 a:b , 열 a:b] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = iris.iloc[:, :4].values\n",
    "y = iris.iloc[:, -1].values\n",
    "X\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y1 = encoder.fit_transform(y)\n",
    "y1 # 0000000,11111111,2222\n",
    "y2 = pd.get_dummies(y1).values\n",
    "y2 # 100, 010, 001  들로 만들어줌\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , y_train , y_test = train_test_split(X, y2, test_size =0.2,\n",
    "                                                      random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\acorn\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\acorn\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 0s 884us/step - loss: 1.0310 - accuracy: 0.4583 - val_loss: 0.9824 - val_accuracy: 0.5667\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.8994 - accuracy: 0.6917 - val_loss: 0.9559 - val_accuracy: 0.5667\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.8358 - accuracy: 0.6917 - val_loss: 0.8845 - val_accuracy: 0.5667\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.7744 - accuracy: 0.7417 - val_loss: 0.7886 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.7144 - accuracy: 0.8750 - val_loss: 0.7369 - val_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.6592 - accuracy: 0.8083 - val_loss: 0.7071 - val_accuracy: 0.6333\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.6022 - accuracy: 0.7833 - val_loss: 0.6493 - val_accuracy: 0.6667\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.5553 - accuracy: 0.8500 - val_loss: 0.6047 - val_accuracy: 0.7000\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.5090 - accuracy: 0.8750 - val_loss: 0.5541 - val_accuracy: 0.7333\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.4769 - accuracy: 0.9417 - val_loss: 0.5007 - val_accuracy: 0.9000\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.4393 - accuracy: 0.9333 - val_loss: 0.4983 - val_accuracy: 0.7333\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.4103 - accuracy: 0.8917 - val_loss: 0.4833 - val_accuracy: 0.7333\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.3820 - accuracy: 0.9417 - val_loss: 0.4196 - val_accuracy: 0.9333\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.3514 - accuracy: 0.9750 - val_loss: 0.4030 - val_accuracy: 0.9000\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.3285 - accuracy: 0.9667 - val_loss: 0.3927 - val_accuracy: 0.9000\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.3097 - accuracy: 0.9667 - val_loss: 0.3825 - val_accuracy: 0.9000\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.2939 - accuracy: 0.9667 - val_loss: 0.3583 - val_accuracy: 0.9333\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.2743 - accuracy: 0.9750 - val_loss: 0.3499 - val_accuracy: 0.9000\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.2591 - accuracy: 0.9667 - val_loss: 0.3348 - val_accuracy: 0.9333\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.2446 - accuracy: 0.9750 - val_loss: 0.3187 - val_accuracy: 0.9333\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.2368 - accuracy: 0.9750 - val_loss: 0.2992 - val_accuracy: 0.9333\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.2219 - accuracy: 0.9750 - val_loss: 0.3128 - val_accuracy: 0.9000\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.2114 - accuracy: 0.9750 - val_loss: 0.2819 - val_accuracy: 0.9333\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.2009 - accuracy: 0.9750 - val_loss: 0.2612 - val_accuracy: 0.9333\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.1898 - accuracy: 0.9833 - val_loss: 0.2744 - val_accuracy: 0.9333\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.1868 - accuracy: 0.9750 - val_loss: 0.2711 - val_accuracy: 0.9333\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 34us/step - loss: 0.1746 - accuracy: 0.9750 - val_loss: 0.2335 - val_accuracy: 0.9333\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.1719 - accuracy: 0.9750 - val_loss: 0.2373 - val_accuracy: 0.9333\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.1626 - accuracy: 0.9750 - val_loss: 0.2330 - val_accuracy: 0.9333\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.1555 - accuracy: 0.9833 - val_loss: 0.2252 - val_accuracy: 0.9333\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 40us/step - loss: 0.1505 - accuracy: 0.9833 - val_loss: 0.2190 - val_accuracy: 0.9333\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 43us/step - loss: 0.1463 - accuracy: 0.9833 - val_loss: 0.2193 - val_accuracy: 0.9333\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.1437 - accuracy: 0.9833 - val_loss: 0.1989 - val_accuracy: 0.9333\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.1396 - accuracy: 0.9833 - val_loss: 0.2135 - val_accuracy: 0.9333\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.1361 - accuracy: 0.9750 - val_loss: 0.1880 - val_accuracy: 0.9667\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.1310 - accuracy: 0.9667 - val_loss: 0.1921 - val_accuracy: 0.9333\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 49us/step - loss: 0.1345 - accuracy: 0.9750 - val_loss: 0.2114 - val_accuracy: 0.9333\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.1277 - accuracy: 0.9667 - val_loss: 0.1774 - val_accuracy: 0.9667\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.1239 - accuracy: 0.9833 - val_loss: 0.1791 - val_accuracy: 0.9333\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.1230 - accuracy: 0.9750 - val_loss: 0.1697 - val_accuracy: 0.9667\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.1239 - accuracy: 0.9667 - val_loss: 0.1919 - val_accuracy: 0.9333\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 34us/step - loss: 0.1137 - accuracy: 0.9750 - val_loss: 0.1597 - val_accuracy: 0.9667\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.1157 - accuracy: 0.9667 - val_loss: 0.1547 - val_accuracy: 0.9667\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.1146 - accuracy: 0.9667 - val_loss: 0.1828 - val_accuracy: 0.9333\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.1100 - accuracy: 0.9750 - val_loss: 0.1642 - val_accuracy: 0.9333\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.1093 - accuracy: 0.9667 - val_loss: 0.1499 - val_accuracy: 0.9667\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.1055 - accuracy: 0.9667 - val_loss: 0.1586 - val_accuracy: 0.9333\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.1037 - accuracy: 0.9833 - val_loss: 0.1598 - val_accuracy: 0.9333\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.1013 - accuracy: 0.9833 - val_loss: 0.1468 - val_accuracy: 0.9667\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.1006 - accuracy: 0.9833 - val_loss: 0.1417 - val_accuracy: 0.9667\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.1029 - accuracy: 0.9667 - val_loss: 0.1346 - val_accuracy: 0.9667\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.1042 - accuracy: 0.9833 - val_loss: 0.1600 - val_accuracy: 0.9333\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 42us/step - loss: 0.1008 - accuracy: 0.9833 - val_loss: 0.1372 - val_accuracy: 0.9667\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.0951 - accuracy: 0.9833 - val_loss: 0.1374 - val_accuracy: 0.9667\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 35us/step - loss: 0.0947 - accuracy: 0.9750 - val_loss: 0.1364 - val_accuracy: 0.9667\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.0936 - accuracy: 0.9833 - val_loss: 0.1386 - val_accuracy: 0.9667\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 34us/step - loss: 0.0925 - accuracy: 0.9833 - val_loss: 0.1333 - val_accuracy: 0.9667\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.0917 - accuracy: 0.9833 - val_loss: 0.1278 - val_accuracy: 0.9667\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 34us/step - loss: 0.0910 - accuracy: 0.9750 - val_loss: 0.1317 - val_accuracy: 0.9667\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.0897 - accuracy: 0.9833 - val_loss: 0.1267 - val_accuracy: 0.9667\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.0888 - accuracy: 0.9833 - val_loss: 0.1213 - val_accuracy: 0.9667\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 34us/step - loss: 0.0896 - accuracy: 0.9667 - val_loss: 0.1199 - val_accuracy: 0.9667\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.0890 - accuracy: 0.9833 - val_loss: 0.1361 - val_accuracy: 0.9333\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.0904 - accuracy: 0.9750 - val_loss: 0.1175 - val_accuracy: 0.9667\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.0905 - accuracy: 0.9667 - val_loss: 0.1122 - val_accuracy: 0.9667\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 34us/step - loss: 0.0870 - accuracy: 0.9667 - val_loss: 0.1167 - val_accuracy: 0.9667\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.0855 - accuracy: 0.9833 - val_loss: 0.1254 - val_accuracy: 0.9667\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.0874 - accuracy: 0.9750 - val_loss: 0.1179 - val_accuracy: 0.9667\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.0835 - accuracy: 0.9667 - val_loss: 0.1034 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 34us/step - loss: 0.0871 - accuracy: 0.9667 - val_loss: 0.1046 - val_accuracy: 0.9667\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.0821 - accuracy: 0.9750 - val_loss: 0.1174 - val_accuracy: 0.9667\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.0824 - accuracy: 0.9833 - val_loss: 0.1105 - val_accuracy: 0.9667\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 32us/step - loss: 0.0825 - accuracy: 0.9833 - val_loss: 0.1049 - val_accuracy: 0.9667\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.0809 - accuracy: 0.9750 - val_loss: 0.0981 - val_accuracy: 0.9667\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 34us/step - loss: 0.0812 - accuracy: 0.9667 - val_loss: 0.1028 - val_accuracy: 0.9667\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.0829 - accuracy: 0.9667 - val_loss: 0.0997 - val_accuracy: 0.9667\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.0801 - accuracy: 0.9833 - val_loss: 0.1153 - val_accuracy: 0.9667\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 40us/step - loss: 0.0812 - accuracy: 0.9750 - val_loss: 0.1027 - val_accuracy: 0.9667\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.0791 - accuracy: 0.9750 - val_loss: 0.0920 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.0828 - accuracy: 0.9750 - val_loss: 0.0998 - val_accuracy: 0.9667\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.0779 - accuracy: 0.9833 - val_loss: 0.0935 - val_accuracy: 0.9667\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.0781 - accuracy: 0.9833 - val_loss: 0.0928 - val_accuracy: 0.9667\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.0809 - accuracy: 0.9667 - val_loss: 0.0891 - val_accuracy: 0.9667\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 32us/step - loss: 0.0842 - accuracy: 0.9667 - val_loss: 0.1076 - val_accuracy: 0.9667\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.0779 - accuracy: 0.9750 - val_loss: 0.0901 - val_accuracy: 0.9667\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.0779 - accuracy: 0.9833 - val_loss: 0.0862 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.0757 - accuracy: 0.9750 - val_loss: 0.0919 - val_accuracy: 0.9667\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.0802 - accuracy: 0.9750 - val_loss: 0.0979 - val_accuracy: 0.9667\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.0814 - accuracy: 0.9667 - val_loss: 0.0837 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.0752 - accuracy: 0.9750 - val_loss: 0.0870 - val_accuracy: 0.9667\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 34us/step - loss: 0.0759 - accuracy: 0.9750 - val_loss: 0.0956 - val_accuracy: 0.9667\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 43us/step - loss: 0.0784 - accuracy: 0.9750 - val_loss: 0.0857 - val_accuracy: 0.9667\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 35us/step - loss: 0.0779 - accuracy: 0.9667 - val_loss: 0.0803 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.0798 - accuracy: 0.9667 - val_loss: 0.0867 - val_accuracy: 0.9667\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.0744 - accuracy: 0.9833 - val_loss: 0.0796 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.0773 - accuracy: 0.9667 - val_loss: 0.0788 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 41us/step - loss: 0.0768 - accuracy: 0.9750 - val_loss: 0.1085 - val_accuracy: 0.9667\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.0793 - accuracy: 0.9750 - val_loss: 0.0826 - val_accuracy: 0.9667\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.0752 - accuracy: 0.9750 - val_loss: 0.0770 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.0761 - accuracy: 0.9833 - val_loss: 0.0856 - val_accuracy: 0.9667\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#입력의 개수는 4가지 속성 넣으니깐 4 출력의 개수는 내맘 64개\n",
    "model.add(Dense(64, input_shape=(4,), activation = \"relu\"))\n",
    "#입력개수 지정안해도됨\n",
    "model.add(Dense(64, activation = \"relu\"))\n",
    "model.add(Dense(3, activation = \"softmax\"))\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", \n",
    "             metrics = [\"accuracy\"])\n",
    "hist = model.fit(X_train, y_train, epochs = 100, validation_data =(X_test,\n",
    "                                                                  y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b0b3aa4f08>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(hist.history.keys())\n",
    "plt.figure(figsize =(12,8) )\n",
    "plt.plot(hist.history[\"loss\"])\n",
    "plt.plot(hist.history[\"val_loss\"])\n",
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history[\"val_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 32us/step\n",
      "0.08558161556720734 0.9666666388511658\n"
     ]
    }
   ],
   "source": [
    "loss, acc=model.evaluate(X_test, y_test)\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      0.92      0.96        13\n",
      "           2       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.95      0.97      0.96        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "[[11  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  0  6]]\n",
      "품종예측 :  ['setosa']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_test_class = np.argmax(y_test, axis = 1)\n",
    "y_pred_class = np.argmax(y_pred, axis = 1)\n",
    "\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "print(confusion_matrix(y_test_class, y_pred_class))\n",
    "\n",
    "test_set = np.array([[5, 2.9, 1, 0.2]])\n",
    "\n",
    "print(\"품종예측 : \", iris[\"species\"].unique()[model.predict_classes(test_set)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 0.2536 - accuracy: 0.9237\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0670 - accuracy: 0.9794\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0500 - accuracy: 0.9847\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.0404 - accuracy: 0.9877\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0343 - accuracy: 0.9891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1b0b42b4988>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras import layers\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# one hot 인코딩\n",
    "y_train= np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "#이미지 데이터 스케일 조정\n",
    "\n",
    "X_train = X_train.reshape((60000, 28,28,1)).astype(\"float32\")/255\n",
    "X_test = X_test.reshape((10000, 28,28,1)).astype(\"float32\")/255\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# conv layer : 필터개수는 32개, 크기는 3 * 3 \n",
    "#한장에 대한 정보 \n",
    "model.add(layers.Conv2D(32, (3,3), activation = \"relu\", input_shape=(28,28,1)))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3,3), activation = \"relu\"))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3,3), activation = \"relu\"))\n",
    "\n",
    "#FC Layer\n",
    "model.add(layers.Flatten())\n",
    "model.add(Dense(64, activation = \"relu\"))\n",
    "model.add(Dense(10, activation = \"softmax\"))\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\",\n",
    "             metrics = [\"accuracy\"])\n",
    "model.fit(X_train, y_train, epochs = 5, batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 90us/step\n",
      "0.031603475481411444 0.9897000193595886\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
